{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Maxent_flying-squirrel.ipynb",
      "authorship_tag": "ABX9TyP4ZSR2QVAz6z30l0YdeMeE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjangmo91/flying-squirrel/blob/main/Maxent_flying_squirrel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
      ],
      "metadata": {
        "id": "HEYQu16Ug83I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy ë²„ì „ 2.0 ë¯¸ë§Œ ë‹¤ìš´ê·¸ë ˆì´ë“œ\n",
        "# !pip install 'numpy<2.0' -q"
      ],
      "metadata": {
        "id": "uA9H5iVQ0wDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmWpfyjqrsgg"
      },
      "outputs": [],
      "source": [
        "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "# !pip install earthengine-api -U -q\n",
        "# !pip install geemap -U -q\n",
        "# !pip install pandas seaborn matplotlib -q\n",
        "# !pip install scikit-learn-extra -q\n",
        "!pip install geojson -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import ee\n",
        "import geemap\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from shapely.geometry import Point\n",
        "from ipyleaflet import WidgetControl\n",
        "from ipywidgets import Label\n",
        "\n",
        "# Earth Engine ì¸ì¦ ë° ì´ˆê¸°í™”\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='ee-jjangmo91')\n",
        "\n",
        "# Google Drive ë§ˆìš´íŠ¸\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VavnykH_thW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. ë°ì´í„° ì¤€ë¹„ (ì¢… ì¶œí˜„, í™˜ê²½ ë³€ìˆ˜)"
      ],
      "metadata": {
        "id": "G1SkEWcLg_bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import os\n",
        "from pyproj import Transformer\n",
        "\n",
        "# ì¢… ì¶œí˜„ ë°ì´í„° ê²½ë¡œ (CSV)\n",
        "csv_path = '/content/drive/MyDrive/KNPS/Siberian flying squirrel/data/Pteromys volnas.csv'\n",
        "\n",
        "# í™˜ê²½ ë³€ìˆ˜ í´ë” ê²½ë¡œ\n",
        "raster_folder = '/content/drive/MyDrive/KNPS/Siberian flying squirrel/data/'\n",
        "\n",
        "# ì‚¬ìš©í•  ë³€ìˆ˜ íŒŒì¼ ëª©ë¡\n",
        "tif_files = {\n",
        "    'elevation': 'Clipped_dem.tif',\n",
        "    'slope': 'Clipped_slope.tif',\n",
        "    'northness': 'Clipped_Northness.tif',\n",
        "    'tpi': 'Clipped_TPI_300.tif',\n",
        "    'twi': 'Clipped_TWI.tif',\n",
        "    'tree_cover': 'Clipped_treecover_focal300.tif',\n",
        "    'forest_age': 'Clipped_age.tif',\n",
        "    'forest_dmcls': 'Clipped_dmcls.tif',\n",
        "    'forest_type': 'Clipped_frtp.tif'\n",
        "}\n",
        "\n",
        "# CSV ì½ê¸°\n",
        "df = pd.read_csv(csv_path)\n",
        "print(f\"1. ì›ë³¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ\")\n",
        "\n",
        "# ì¢Œí‘œ ë³€í™˜ê¸° ìƒì„± (WGS84 -> Korea Central Belt 2010)\n",
        "transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:5186\", always_xy=True)\n",
        "\n",
        "# ì¢Œí‘œ ë³€í™˜ ì‹¤í–‰\n",
        "xx, yy = transformer.transform(df['longitude'].values, df['latitude'].values)\n",
        "\n",
        "# ë³€í™˜ëœ ì¢Œí‘œë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€ (ê²€ì¦ìš©)\n",
        "df['X_5186'] = xx\n",
        "df['Y_5186'] = yy\n",
        "\n",
        "print(\"2. ì¢Œí‘œ ë³€í™˜ ì™„ë£Œ (EPSG:4326 -> EPSG:5186)\")\n",
        "print(f\"   - ì˜ˆì‹œ ë³€í™˜: ({df['longitude'][0]:.4f}, {df['latitude'][0]:.4f}) -> ({df['X_5186'][0]:.1f}, {df['Y_5186'][0]:.1f})\")\n",
        "\n",
        "# ë˜ìŠ¤í„° ê°’ ì¶”ì¶œ\n",
        "print(\"\\n3. í™˜ê²½ ë³€ìˆ˜ê°’ ì¶”ì¶œ ì‹œì‘...\")\n",
        "\n",
        "# ë³€í™˜ëœ 5186 ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
        "coords_5186 = [(x, y) for x, y in zip(df['X_5186'], df['Y_5186'])]\n",
        "\n",
        "for var_name, file_name in tif_files.items():\n",
        "    full_path = os.path.join(raster_folder, file_name)\n",
        "\n",
        "    if os.path.exists(full_path):\n",
        "        try:\n",
        "            with rasterio.open(full_path) as src:\n",
        "                if var_name == 'elevation':\n",
        "                    print(f\"   - ë˜ìŠ¤í„° ì¢Œí‘œê³„ í™•ì¸: {src.crs}\")\n",
        "                sampled_values = [x[0] for x in src.sample(coords_5186)]\n",
        "                df[var_name] = sampled_values\n",
        "                print(f\"   - [ì„±ê³µ] {var_name} ì¶”ì¶œ ì™„ë£Œ\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   - [ì—ëŸ¬] {var_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "    else:\n",
        "        print(f\"   - [ê²½ê³ ] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {full_path}\")\n",
        "\n",
        "# ë°ì´í„° ì •ì œ(NoData ì œê±°)\n",
        "original_count = len(df)\n",
        "\n",
        "if 'elevation' in df.columns:\n",
        "    df_final = df[df['elevation'] > -9000].copy()\n",
        "else:\n",
        "    df_final = df.copy()\n",
        "\n",
        "# í˜¹ì‹œ ëª¨ë¥¼ ê²°ì¸¡ì¹˜(NaN) ì œê±°\n",
        "df_final = df_final.dropna()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"ìµœì¢… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ\")\n",
        "print(f\" - ì›ë³¸ ì¢Œí‘œ ìˆ˜: {original_count}\")\n",
        "print(f\" - ìœ íš¨ ì¢Œí‘œ ìˆ˜: {len(df_final)} (ê²½ê³„ ë°–/NoData ì œê±°ë¨)\")\n",
        "print(f\" - ì¶”ì¶œëœ ë³€ìˆ˜: {list(tif_files.keys())}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
        "display(df_final[['longitude', 'latitude', 'elevation', 'forest_type']].head())\n",
        "\n",
        "# (ì„ íƒ) CSVë¡œ ì €ì¥í•˜ê³  ì‹¶ë‹¤ë©´ ì£¼ì„ í•´ì œ\n",
        "# df_final.to_csv('/content/drive/MyDrive/KNPS/Deer/SDM/Data/model_input_data.csv', index=False)"
      ],
      "metadata": {
        "id": "ZcGiauSYr5OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'df_final' not in locals() or df_final.empty:\n",
        "    print(\"Error: df_final data not found.\")\n",
        "else:\n",
        "    m = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "    m.add_basemap('HYBRID')\n",
        "\n",
        "    points_ee = geemap.pandas_to_ee(\n",
        "        df_final,\n",
        "        latitude='latitude',\n",
        "        longitude='longitude'\n",
        "    )\n",
        "\n",
        "    point_params = {\n",
        "        'color': 'ff0000',\n",
        "        'fillColor': 'ff0000',\n",
        "        'pointSize': 5,\n",
        "        'width': 1\n",
        "    }\n",
        "\n",
        "    m.addLayer(points_ee.style(**point_params), {}, 'Siberian Flying Squirrel')\n",
        "\n",
        "    legend_dict = {\n",
        "        \"Siberian Flying Squirrel\": \"ff0000\"\n",
        "    }\n",
        "    m.add_legend(title=\"Legend\", legend_dict=legend_dict, position='bottomright')\n",
        "\n",
        "    display(m)"
      ],
      "metadata": {
        "id": "PYImSNt9CPeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„ ë° ë³€ìˆ˜ ì„ íƒ"
      ],
      "metadata": {
        "id": "_LAZ7oZCwKF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# ë°ì´í„° í´ë¦¬ë‹\n",
        "cols_to_check = [\n",
        "    'elevation', 'slope', 'northness', 'tpi', 'twi',\n",
        "    'tree_cover', 'forest_age', 'forest_dmcls', 'forest_type'\n",
        "]\n",
        "\n",
        "print(f\"ì •ì œ ì „ ë°ì´í„° ìˆ˜: {len(df_final)}\")\n",
        "df_cleaned = df_final.copy()\n",
        "\n",
        "for col in cols_to_check:\n",
        "    if col in df_cleaned.columns:\n",
        "        # -9000 ë¯¸ë§Œ ë˜ëŠ” 10000 ì´ˆê³¼(1e38) ê°’ ì œê±°\n",
        "        df_cleaned[col] = df_cleaned[col].apply(lambda x: np.nan if (x < -9000 or x > 10000) else x)\n",
        "\n",
        "# ê²°ì¸¡ì¹˜ê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ” í–‰ ì‚­ì œ\n",
        "df_cleaned = df_cleaned.dropna(subset=cols_to_check)\n",
        "\n",
        "print(f\"ì •ì œ í›„ ë°ì´í„° ìˆ˜: {len(df_cleaned)}\")"
      ],
      "metadata": {
        "id": "GDIKAedxivj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
        "correlation_matrix = df_cleaned[cols_to_check].corr()\n",
        "\n",
        "# íˆíŠ¸ë§µ ê·¸ë¦¬ê¸°\n",
        "sns.heatmap(\n",
        "    correlation_matrix,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap='coolwarm',\n",
        "    vmin=-1, vmax=1,\n",
        "    linewidths=.5\n",
        ")\n",
        "\n",
        "plt.title('Correlation Matrix (Pearson)', fontsize=16, fontweight='bold')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PkK7ZgjAOEj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tools.tools import add_constant\n",
        "\n",
        "# ìƒìˆ˜í•­ ì¶”ê°€\n",
        "df_vif_input = add_constant(df_cleaned[cols_to_check])\n",
        "\n",
        "# VIF ê³„ì‚° ìˆ˜í–‰\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = df_vif_input.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(df_vif_input.values, i)\n",
        "                   for i in range(len(df_vif_input.columns))]\n",
        "\n",
        "# ê²°ê³¼ ì •ë¦¬\n",
        "vif_data = vif_data[vif_data['feature'] != 'const']\n",
        "\n",
        "# ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬\n",
        "vif_sorted = vif_data.sort_values(by='VIF', ascending=False)\n",
        "\n",
        "# í‘œ ì¶œë ¥\n",
        "print(\"\\n[ìƒìˆ˜í•­ ì¶”ê°€ í›„ VIF ê³„ì‚° ê²°ê³¼]\")\n",
        "print(vif_sorted.to_string(index=False))\n",
        "\n",
        "# ê·¸ë˜í”„\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='VIF', y='feature', data=vif_sorted, palette='viridis')\n",
        "\n",
        "# ê¸°ì¤€ì„  ì¶”ê°€ (5=ì£¼ì˜, 10=ìœ„í—˜)\n",
        "plt.axvline(x=5, color='orange', linestyle='--', label='Warning (VIF=5)')\n",
        "plt.axvline(x=10, color='red', linestyle='--', label='Danger (VIF=10)')\n",
        "\n",
        "plt.title('Variance Inflation Factor (VIF) - Corrected', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('VIF Value')\n",
        "plt.ylabel('')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jOnl3oTVOI_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograms\n",
        "print(\"\\n[ë³€ìˆ˜ë³„ ë°ì´í„° ë¶„í¬]\")\n",
        "df_cleaned[cols_to_check].hist(bins=30, figsize=(15, 12), layout=(3, 3), color='#2ca02c')\n",
        "plt.suptitle(\"Variable Distributions (Cleaned)\", fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z2wNJ-qiOPy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Presence-Background ë°ì´í„° ìƒì„±"
      ],
      "metadata": {
        "id": "ivKlWuWlLM20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyproj import Transformer\n",
        "\n",
        "# Background Point ìƒì„± ê°œìˆ˜ ì„¤ì •\n",
        "NUM_BACKGROUND = 2000\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "print(f\"ë°°ê²½ì (Pseudo-absence) {NUM_BACKGROUND}ê°œë¥¼ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "\n",
        "# ê¸°ì¤€ì´ ë˜ëŠ” ë˜ìŠ¤í„° íŒŒì¼\n",
        "dem_path = os.path.join(raster_folder, 'Clipped_dem.tif')\n",
        "transformer_inv = Transformer.from_crs(\"epsg:5186\", \"epsg:4326\", always_xy=True)\n",
        "\n",
        "# ìœ íš¨í•œ í”½ì…€ì—ì„œ ëœë¤ ì¢Œí‘œ ì¶”ì¶œ\n",
        "with rasterio.open(dem_path) as src:\n",
        "    data = src.read(1)\n",
        "    valid_indices = np.where((data > -9000) & (data < 10000))\n",
        "    num_valid_pixels = len(valid_indices[0])\n",
        "    print(f\" - ì „ì²´ ìœ íš¨ í”½ì…€ ìˆ˜: {num_valid_pixels}ê°œ\")\n",
        "    if num_valid_pixels > NUM_BACKGROUND:\n",
        "        # ì¤‘ë³µ ì—†ì´ ì¸ë±ìŠ¤ ì„ íƒ\n",
        "        random_idx = np.random.choice(num_valid_pixels, NUM_BACKGROUND, replace=False)\n",
        "        # ì„ íƒëœ ì¸ë±ìŠ¤ì˜ í–‰(row), ì—´(col) ê°€ì ¸ì˜¤ê¸°\n",
        "        rand_rows = valid_indices[0][random_idx]\n",
        "        rand_cols = valid_indices[1][random_idx]\n",
        "    else:\n",
        "        print(\"ê²½ê³ : ë°°ê²½ì  ê°œìˆ˜ê°€ ìœ íš¨ í”½ì…€ ìˆ˜ë³´ë‹¤ ë§ìŠµë‹ˆë‹¤. ì „ì²´ í”½ì…€ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "        rand_rows = valid_indices[0]\n",
        "        rand_cols = valid_indices[1]\n",
        "\n",
        "    xs, ys = rasterio.transform.xy(src.transform, rand_rows, rand_cols)\n",
        "    lons, lats = transformer_inv.transform(xs, ys)\n",
        "\n",
        "# ë°°ê²½ ë°ì´í„°í”„ë ˆì„ ì´ˆê¸°í™”\n",
        "df_background = pd.DataFrame({\n",
        "    'longitude': lons,\n",
        "    'latitude': lats,\n",
        "    'X_5186': xs,\n",
        "    'Y_5186': ys\n",
        "})\n",
        "\n",
        "# í™˜ê²½ ë³€ìˆ˜ ê°’ ì¶”ì¶œ\n",
        "coords_5186 = [(x, y) for x, y in zip(df_background['X_5186'], df_background['Y_5186'])]\n",
        "\n",
        "for var_name, file_name in tif_files.items():\n",
        "    full_path = os.path.join(raster_folder, file_name)\n",
        "    if os.path.exists(full_path):\n",
        "        with rasterio.open(full_path) as src:\n",
        "            # ì¢Œí‘œ ìœ„ì¹˜ì˜ ê°’ ìƒ˜í”Œë§\n",
        "            sampled_values = [x[0] for x in src.sample(coords_5186)]\n",
        "            df_background[var_name] = sampled_values\n",
        "    else:\n",
        "        print(f\"\\n[ê²½ê³ ] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_name}\")\n",
        "print(\"ì™„ë£Œ!\")\n",
        "\n",
        "# ë°ì´í„° ë³‘í•© ë° ì •ë¦¬ (Presence + Background)\n",
        "df_presence = df_cleaned.copy()\n",
        "df_presence['pa'] = 1  # Presence = 1\n",
        "df_background['pa'] = 0  # Background = 0\n",
        "common_cols = list(set(df_presence.columns) & set(df_background.columns))\n",
        "final_modeling_df = pd.concat([df_presence[common_cols], df_background[common_cols]], ignore_index=True)\n",
        "cols_env = list(tif_files.keys()) # í™˜ê²½ë³€ìˆ˜ ì»¬ëŸ¼ë“¤\n",
        "\n",
        "for col in cols_env:\n",
        "    if col in final_modeling_df.columns:\n",
        "        final_modeling_df[col] = final_modeling_df[col].apply(lambda x: np.nan if (x < -9000 or x > 10000) else x)\n",
        "\n",
        "# NaN ì œê±°\n",
        "before_len = len(final_modeling_df)\n",
        "final_modeling_df = final_modeling_df.dropna()\n",
        "print(f\" - ìµœì¢… ì •ì œ í›„ ì‚­ì œëœ ë°°ê²½ì  ìˆ˜: {before_len - len(final_modeling_df)}ê°œ\")\n",
        "\n",
        "# ê²°ê³¼ í™•ì¸ ë° ì €ì¥\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"ìµœì¢… ëª¨ë¸ë§ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ\")\n",
        "print(f\" - ì´ ë°ì´í„° ìˆ˜: {len(final_modeling_df)} ê°œ\")\n",
        "print(f\" - Presence (1): {len(final_modeling_df[final_modeling_df['pa']==1])} ê°œ (í•˜ëŠ˜ë‹¤ëŒì¥)\")\n",
        "print(f\" - Background (0): {len(final_modeling_df[final_modeling_df['pa']==0])} ê°œ (ê°€ì§œ ë¶€ì¬ì )\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# ì €ì¥\n",
        "SAVE_PATH = '/content/drive/MyDrive/KNPS/Siberian flying squirrel/data/final_modeling_data_v1.csv'\n",
        "# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
        "os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n",
        "\n",
        "final_modeling_df.to_csv(SAVE_PATH, index=False)\n",
        "print(f\"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {SAVE_PATH}\")\n",
        "\n",
        "# ë¯¸ë¦¬ë³´ê¸°\n",
        "display(final_modeling_df.head())\n",
        "display(final_modeling_df.tail())"
      ],
      "metadata": {
        "id": "jAb9BA-l3423"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Spatial Block Cross-Validation"
      ],
      "metadata": {
        "id": "-Mugp5Z3lxZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê¸°ì¤€ íŒŒì¼ ê²½ë¡œ\n",
        "dem_path = os.path.join(raster_folder, 'Clipped_dem.tif')\n",
        "\n",
        "try:\n",
        "    with rasterio.open(dem_path) as src:\n",
        "        local_crs = src.crs.to_string()\n",
        "        bounds = src.bounds\n",
        "        bbox = [bounds.left, bounds.bottom, bounds.right, bounds.top]\n",
        "        print(f\" - ì°¸ì¡° íŒŒì¼: {os.path.basename(dem_path)}\")\n",
        "        print(f\" - ì¢Œí‘œê³„: {local_crs}\")\n",
        "        print(f\" - ë²”ìœ„(Bounds): {bbox}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"TIF íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "# ê²©ì ìƒì„±\n",
        "BLOCK_SCALE = 2000\n",
        "tif_geometry = ee.Geometry.Rectangle(bbox, proj='EPSG:5186', geodesic=False)\n",
        "grid = tif_geometry.coveringGrid(proj='EPSG:5186', scale=BLOCK_SCALE)\n",
        "grid_random = grid.randomColumn(seed=42)\n",
        "\n",
        "# 7:3 ë¹„ìœ¨ë¡œ ë¶„í• \n",
        "split_threshold = 0.7\n",
        "grid_classified = grid_random.map(lambda f: f.set('group', ee.Number(f.get('random')).gte(split_threshold)))\n",
        "print(f\" - ë¸”ë¡ í¬ê¸°: {BLOCK_SCALE}m\")\n",
        "print(\" - ê²©ì ìƒì„± ì™„ë£Œ (ë¡œì»¬ TIF ë²”ìœ„ ê¸°ì¤€).\")\n",
        "\n",
        "# ë¡œì»¬ ë°ì´í„°ì— ë¸”ë¡ ì •ë³´ ë§¤í•‘\n",
        "try:\n",
        "    # ë¡œì»¬ ë°ì´í„°í”„ë ˆì„ ì—…ë¡œë“œ\n",
        "    points_ee = geemap.pandas_to_ee(\n",
        "        final_modeling_df[['latitude', 'longitude']],\n",
        "        latitude_col='latitude',\n",
        "        longitude_col='longitude'\n",
        "    )\n",
        "\n",
        "    # ê° í¬ì¸íŠ¸ê°€ ì†í•œ ê²©ìì˜ group ê°’ ê°€ì ¸ì˜¤ê¸°\n",
        "    def get_group(feat):\n",
        "        intersects = grid_classified.filterBounds(feat.geometry())\n",
        "        first_grid = ee.Feature(intersects.first())\n",
        "        group_val = ee.Algorithms.If(first_grid, first_grid.get('group'), -1)\n",
        "        return feat.set('group', group_val)\n",
        "    points_with_group = points_ee.map(get_group)\n",
        "    group_info = points_with_group.getInfo()\n",
        "    group_values = []\n",
        "    for f in group_info['features']:\n",
        "        val = f['properties'].get('group')\n",
        "        if val is None: val = -1\n",
        "        group_values.append(val)\n",
        "    final_modeling_df['group'] = group_values\n",
        "\n",
        "    # ê²©ì ë°– í¬ì¸íŠ¸ í™•ì¸\n",
        "    invalid_count = len(final_modeling_df[final_modeling_df['group'] == -1])\n",
        "    if invalid_count > 0:\n",
        "        print(f\"TIF ë²”ìœ„ ë°– í¬ì¸íŠ¸ {invalid_count}ê°œ ë°œê²¬. (ì œì™¸ ì²˜ë¦¬)\")\n",
        "        final_modeling_df = final_modeling_df[final_modeling_df['group'] != -1]\n",
        "    else:\n",
        "        print(\"ëª¨ë“  í¬ì¸íŠ¸ê°€ TIF ê²©ì ë‚´ì— ì •ìƒì ìœ¼ë¡œ ìœ„ì¹˜í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "    # 4. ë°ì´í„° ë¶„í•  (Train / Test)\n",
        "    train_df = final_modeling_df[final_modeling_df['group'] == 0].copy()\n",
        "    test_df = final_modeling_df[final_modeling_df['group'] == 1].copy()\n",
        "\n",
        "    # ì»¬ëŸ¼ ì •ë¦¬\n",
        "    train_df.drop(columns=['group'], inplace=True)\n",
        "    test_df.drop(columns=['group'], inplace=True)\n",
        "\n",
        "    print(\"\\n[ê³µê°„ ë¶„í• (Spatial CV) ê²°ê³¼]\")\n",
        "    print(f\" - í›ˆë ¨ ì„¸íŠ¸ (Training): {len(train_df)}ê°œ ({(len(train_df)/len(final_modeling_df))*100:.1f}%)\")\n",
        "    print(f\"   ã„´ Presence: {len(train_df[train_df['pa']==1])}, Background: {len(train_df[train_df['pa']==0])}\")\n",
        "\n",
        "    print(f\" - í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ (Testing): {len(test_df)}ê°œ ({(len(test_df)/len(final_modeling_df))*100:.1f}%)\")\n",
        "    print(f\"   ã„´ Presence: {len(test_df[test_df['pa']==1])}, Background: {len(test_df[test_df['pa']==0])}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "# ì‹œê°í™”\n",
        "m = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "m.add_basemap('HYBRID')\n",
        "\n",
        "# í›ˆë ¨ìš© ë¸”ë¡ (íŒŒë€ìƒ‰)\n",
        "train_blocks = grid_classified.filter(ee.Filter.eq('group', 0))\n",
        "m.addLayer(train_blocks.style(**{'color': '0000FF', 'fillColor': '0000FF22'}), {}, 'Training Blocks (Blue)')\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ìš© ë¸”ë¡ (ë¹¨ê°„ìƒ‰)\n",
        "test_blocks = grid_classified.filter(ee.Filter.eq('group', 1))\n",
        "m.addLayer(test_blocks.style(**{'color': 'FF0000', 'fillColor': 'FF000022'}), {}, 'Testing Blocks (Red)')\n",
        "\n",
        "# Presence í¬ì¸íŠ¸\n",
        "presence_viz = geemap.pandas_to_ee(final_modeling_df[final_modeling_df['pa']==1], 'latitude', 'longitude')\n",
        "m.addLayer(presence_viz.style(**{'color': 'ffff00', 'pointSize': 4}), {}, 'Presence Points')\n",
        "\n",
        "# 4) TIF ë²”ìœ„ ê²½ê³„ (ì´ˆë¡ìƒ‰ ì„ )\n",
        "tif_boundary_fc = ee.FeatureCollection([ee.Feature(tif_geometry)])\n",
        "m.addLayer(tif_boundary_fc.style(**{'color': '00FF00', 'fillColor': '00000000', 'width': 2}), {}, 'TIF Bounds')\n",
        "m.add_legend(title=\"Spatial CV (Based on TIF)\", legend_dict={\n",
        "    \"Training Grid\": \"0000FF\",\n",
        "    \"Testing Grid\": \"FF0000\",\n",
        "    \"Presence\": \"ffff00\",\n",
        "    \"TIF Boundary\": \"00FF00\"\n",
        "})\n",
        "\n",
        "display(m)"
      ],
      "metadata": {
        "id": "NbMN09DD_9wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. MaxEnt í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° ëª¨ë¸ í›ˆë ¨"
      ],
      "metadata": {
        "id": "XR1hHTGNncUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "try:\n",
        "    training_fc = geemap.pandas_to_ee(train_df, latitude_col='latitude', longitude_col='longitude')\n",
        "    testing_fc = geemap.pandas_to_ee(test_df, latitude_col='latitude', longitude_col='longitude')\n",
        "\n",
        "    print(\"Pandas ë°ì´í„°í”„ë ˆì„ì„ GEE FeatureCollectionìœ¼ë¡œ ë³€í™˜ ì™„ë£Œ.\")\n",
        "    print(f\" - í›ˆë ¨ ë°ì´í„°: {training_fc.size().getInfo()} ê°œ\")\n",
        "    print(f\" - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {testing_fc.size().getInfo()} ê°œ\")\n",
        "\n",
        "except NameError:\n",
        "    print(\" ì˜¤ë¥˜: 'train_df'ë‚˜ 'test_df'ê°€ ì—†ìŠµë‹ˆë‹¤. ë°”ë¡œ ì• ë‹¨ê³„(ê³µê°„ ë¶„í• ) ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "except Exception as e:\n",
        "    print(f\" ë°ì´í„° ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì„¤ì •\n",
        "if 'cols_to_check' in locals():\n",
        "    feature_bands = cols_to_check\n",
        "else:\n",
        "    # cols_to_checkê°€ ì—†ìœ¼ë©´ train_dfì—ì„œ ì§ì ‘ ì¶”ì¶œ\n",
        "    exclude_cols = ['pa', 'latitude', 'longitude', 'group', 'geometry', 'system:index', 'const']\n",
        "    feature_bands = [c for c in train_df.columns if c not in exclude_cols]\n",
        "\n",
        "print(f\"í•™ìŠµì— ì‚¬ìš©í•  ë…ë¦½ë³€ìˆ˜ ({len(feature_bands)}ê°œ): {feature_bands}\")\n",
        "\n",
        "best_auc = -1\n",
        "best_params = {}\n",
        "tuning_results = []\n",
        "\n",
        "# íŠœë‹ ë²”ìœ„ ì„¤ì •\n",
        "reg_multipliers = [0.5, 1.0, 1.5, 2.0, 3.0, 5.0]\n",
        "auto_feature_options = [True, False]\n",
        "\n",
        "print(\"\\n í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë£¨í”„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "# íŠœë‹ ë£¨í”„ ì‹¤í–‰\n",
        "for multiplier in reg_multipliers:\n",
        "    for auto_feat in auto_feature_options:\n",
        "        try:\n",
        "            maxent_model = ee.Classifier.amnhMaxent(\n",
        "                betaMultiplier=multiplier,\n",
        "                autoFeature=auto_feat,\n",
        "                addSamplesToBackground=True\n",
        "            )\n",
        "\n",
        "            # ëª¨ë¸ í›ˆë ¨\n",
        "            trained_model = maxent_model.train(\n",
        "                features=training_fc,\n",
        "                classProperty='pa',\n",
        "                inputProperties=feature_bands\n",
        "            )\n",
        "\n",
        "            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡\n",
        "            classified_test = testing_fc.classify(trained_model)\n",
        "\n",
        "            # ê²°ê³¼ íšŒìˆ˜\n",
        "            predicted_df = geemap.ee_to_df(classified_test.select(['pa', 'probability']))\n",
        "\n",
        "            if predicted_df is not None and not predicted_df.empty:\n",
        "                true_labels = predicted_df['pa']\n",
        "                pred_scores = predicted_df['probability']\n",
        "\n",
        "                # AUC ê³„ì‚° ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "                if len(true_labels.unique()) < 2:\n",
        "                    # print(f\" [Skip] ... í´ë˜ìŠ¤ ë¶ˆê· í˜•\")\n",
        "                    continue\n",
        "\n",
        "                auc_score = roc_auc_score(true_labels, pred_scores)\n",
        "\n",
        "                result_str = f\" - Beta: {multiplier}, Auto: {auto_feat} -> AUC: {auc_score:.4f}\"\n",
        "                print(result_str)\n",
        "                tuning_results.append(result_str)\n",
        "\n",
        "                # ìµœê³  ì„±ëŠ¥ ê°±ì‹ \n",
        "                if auc_score > best_auc:\n",
        "                    best_auc = auc_score\n",
        "                    best_params['betaMultiplier'] = multiplier\n",
        "                    best_params['autoFeature'] = auto_feat\n",
        "            else:\n",
        "                print(\" [Error] ì˜ˆì¸¡ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" [Error] íŠœë‹ ì¤‘ ì˜¤ë¥˜ (Beta: {multiplier}): {e}\")\n",
        "            continue\n",
        "\n",
        "# ìµœì  ëª¨ë¸ í™•ì • ë° ì¬í›ˆë ¨\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "if best_params:\n",
        "    print(f\" - Beta Multiplier: {best_params['betaMultiplier']}\")\n",
        "    print(f\" - Auto Feature: {best_params['autoFeature']}\")\n",
        "    print(f\" - ìµœê³  AUC ì ìˆ˜: {best_auc:.4f}\")\n",
        "    print(\"\\nìµœì  íŒŒë¼ë¯¸í„°ë¡œ 'ìµœì¢… ëª¨ë¸(Final Model)'ì„ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "    # ìµœì  íŒŒë¼ë¯¸í„° ì ìš©í•˜ì—¬ ìµœì¢… ëª¨ë¸ ìƒì„±\n",
        "    final_model = ee.Classifier.amnhMaxent(\n",
        "        betaMultiplier=best_params['betaMultiplier'],\n",
        "        autoFeature=best_params['autoFeature'],\n",
        "        addSamplesToBackground=True\n",
        "    ).train(\n",
        "        features=training_fc,\n",
        "        classProperty='pa',\n",
        "        inputProperties=feature_bands\n",
        "    )\n",
        "\n",
        "    print(\"ìµœì¢… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ.\")\n",
        "else:\n",
        "    print(\"ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "zR87Rh0OhQLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. ëª¨ë¸ ì í•©ì„± í‰ê°€"
      ],
      "metadata": {
        "id": "uqy23jNFMU-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "print(\"ìµœì¢… ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì˜ ì˜ˆì¸¡ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "try:\n",
        "    # classify ì‹¤í–‰ -> 'probability' ì»¬ëŸ¼ ìƒì„±\n",
        "    classified_test_final = testing_fc.classify(final_model, 'probability')\n",
        "\n",
        "    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•´ì„œ ê°€ì ¸ì˜´\n",
        "    predicted_df = geemap.ee_to_df(classified_test_final.select(['pa', 'probability']))\n",
        "\n",
        "    # ë°ì´í„° íƒ€ì… ë³€í™˜\n",
        "    predicted_df['pa'] = predicted_df['pa'].astype(int)\n",
        "    predicted_df['probability'] = predicted_df['probability'].astype(float)\n",
        "\n",
        "    print(f\"ì˜ˆì¸¡ ì™„ë£Œ. (ë°ì´í„° ìˆ˜: {len(predicted_df)}ê°œ)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "# ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° (AUC, TSS)\n",
        "true_labels = predicted_df['pa']\n",
        "pred_scores = predicted_df['probability']\n",
        "\n",
        "# AUC ì ìˆ˜ ê³„ì‚°\n",
        "print(\"\\n--- [ì„±ëŠ¥ í‰ê°€ ê²°ê³¼] ---\")\n",
        "auc_score = roc_auc_score(true_labels, pred_scores)\n",
        "print(f\"AUC (Area Under the Curve): {auc_score:.4f}\")\n",
        "\n",
        "# ìµœì ì˜ ì„ê³„ê°’(Threshold) ë° TSS ì°¾ê¸°\n",
        "print(\"ìµœì ì˜ ì„ê³„ê°’(Threshold) íƒìƒ‰ ì¤‘...\")\n",
        "thresholds = np.linspace(0.0, 1.0, 101)\n",
        "tss_scores = []\n",
        "sensitivity_scores = []\n",
        "specificity_scores = []\n",
        "\n",
        "for t in thresholds:\n",
        "    # í™•ë¥ ì´ të³´ë‹¤ í¬ë©´ 1(ì¶œí˜„), ì‘ìœ¼ë©´ 0(ë¹„ì¶œí˜„)\n",
        "    pred_labels = (pred_scores >= t).astype(int)\n",
        "\n",
        "    # í˜¼ë™ í–‰ë ¬ ê³„ì‚°\n",
        "    tn, fp, fn, tp = confusion_matrix(true_labels, pred_labels).ravel()\n",
        "\n",
        "    # ë¯¼ê°ë„(Sensitivity) & íŠ¹ì´ë„(Specificity)\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    # TSS (True Skill Statistic) = ë¯¼ê°ë„ + íŠ¹ì´ë„ - 1\n",
        "    tss = sensitivity + specificity - 1\n",
        "\n",
        "    tss_scores.append(tss)\n",
        "    sensitivity_scores.append(sensitivity)\n",
        "    specificity_scores.append(specificity)\n",
        "\n",
        "# ìµœì ê°’ ì¶”ì¶œ\n",
        "max_tss_index = np.argmax(tss_scores)\n",
        "optimal_threshold = thresholds[max_tss_index]\n",
        "max_tss = tss_scores[max_tss_index]\n",
        "\n",
        "print(f\"\\n--- ìµœì  ì„ê³„ê°’ ë° ì£¼ìš” ì§€í‘œ ---\")\n",
        "print(f\"ìµœì  ì„ê³„ê°’ (Max TSS): {optimal_threshold:.4f}\")\n",
        "print(f\" - ìµœëŒ€ TSS ì ìˆ˜: {max_tss:.4f}\")\n",
        "print(f\" - ë¯¼ê°ë„ (Sensitivity): {sensitivity_scores[max_tss_index]:.4f} (ì‹¤ì œ ìˆëŠ” ê³³ì„ ë§ì¶œ í™•ë¥ )\")\n",
        "print(f\" - íŠ¹ì´ë„ (Specificity): {specificity_scores[max_tss_index]:.4f} (ì‹¤ì œ ì—†ëŠ” ê³³ì„ ë§ì¶œ í™•ë¥ )\")\n",
        "\n",
        "# \\ê²°ê³¼ ì‹œê°í™” (ROC Curve & Threshold Plot)\n",
        "print(\"\\ní‰ê°€ ì§€í‘œë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤...\")\n",
        "fpr, tpr, _ = roc_curve(true_labels, pred_scores)\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "# ROC Curve\n",
        "ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
        "ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "ax1.set_xlim([0.0, 1.0])\n",
        "ax1.set_ylim([0.0, 1.05])\n",
        "ax1.set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
        "ax1.set_ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
        "ax1.set_title('Receiver Operating Characteristic (ROC) Curve', fontsize=16)\n",
        "ax1.legend(loc=\"lower right\")\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Metrics vs. Threshold\n",
        "ax2.plot(thresholds, tss_scores, label='TSS', color='blue', lw=2)\n",
        "ax2.plot(thresholds, sensitivity_scores, label='Sensitivity', color='green', linestyle='--', alpha=0.7)\n",
        "ax2.plot(thresholds, specificity_scores, label='Specificity', color='red', linestyle='--', alpha=0.7)\n",
        "\n",
        "# ìµœì  ì„ê³„ê°’ í‘œì‹œì„ \n",
        "ax2.axvline(optimal_threshold, color='purple', linestyle=':', lw=2, label=f'Optimal Threshold ({optimal_threshold:.2f})')\n",
        "\n",
        "ax2.set_title('Metrics vs. Threshold', fontsize=16)\n",
        "ax2.set_xlabel('Threshold (Probability Cutoff)', fontsize=12)\n",
        "ax2.set_ylabel('Score', fontsize=12)\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j-5jnIP5MW1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# ë²”ì£¼í˜•/ìˆœì„œí˜•\n",
        "discrete_vars = ['forest_age', 'forest_dmcls', 'forest_type']\n",
        "\n",
        "# ë¶„ì„í•  ì „ì²´ ë³€ìˆ˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
        "if 'feature_bands' in locals():\n",
        "    predictor_names = feature_bands\n",
        "else:\n",
        "    # ë³€ìˆ˜ëª…ì´ ì—†ìœ¼ë©´ train_dfì—ì„œ ì œì™¸í•  ê²ƒ ë¹¼ê³  ê°€ì ¸ì˜¤ê¸°\n",
        "    exclude_cols = ['pa', 'latitude', 'longitude', 'group', 'geometry', 'system:index', 'const']\n",
        "    predictor_names = [c for c in train_df.columns if c not in exclude_cols]\n",
        "\n",
        "# ë‚˜ë¨¸ì§€ ë³€ìˆ˜ë“¤ì˜ í‰ê· ê°’ ê³„ì‚° (ê³ ì •ê°’ìœ¼ë¡œ ì‚¬ìš©)\n",
        "mean_values = train_df[predictor_names].mean()\n",
        "\n",
        "print(f\"ë³€ìˆ˜ ìœ í˜• ì„¤ì • ì™„ë£Œ\")\n",
        "print(f\" - ë§‰ëŒ€ ê·¸ë˜í”„(Bar): {discrete_vars}\")\n",
        "print(f\" - ì„  ê·¸ë˜í”„(Line): ë‚˜ë¨¸ì§€ {len(predictor_names) - len(discrete_vars)}ê°œ ë³€ìˆ˜\")\n",
        "\n",
        "# ê·¸ë˜í”„ ì„¤ì • (3x3 ê·¸ë¦¬ë“œ)\n",
        "n_cols = 3\n",
        "n_rows = math.ceil(len(predictor_names) / n_cols)\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5 * n_rows))\n",
        "axes = axes.flatten()\n",
        "fig.suptitle('Response Curves (Bar for Categorical, Line for Continuous)', fontsize=22, fontweight='bold')\n",
        "\n",
        "# ë°˜ì‘ ê³¡ì„  ìƒì„± ë° ì‹œê°í™”\n",
        "print(\"\\në°˜ì‘ ê³¡ì„  ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "\n",
        "for i, var_to_plot in enumerate(predictor_names):\n",
        "    if var_to_plot in discrete_vars:\n",
        "        # ë²”ì£¼í˜•: ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” ê³ ìœ ê°’(Unique)ë§Œ ë”± ë½‘ì•„ì„œ ì‚¬ìš©\n",
        "        value_range = np.sort(train_df[var_to_plot].unique())\n",
        "        is_categorical = True\n",
        "    else:\n",
        "        # ì—°ì†í˜•\n",
        "        min_val = train_df[var_to_plot].min()\n",
        "        max_val = train_df[var_to_plot].max()\n",
        "        value_range = np.linspace(min_val, max_val, 50)\n",
        "        is_categorical = False\n",
        "\n",
        "    features_to_classify = []\n",
        "    base_properties = mean_values.to_dict()\n",
        "\n",
        "    for val in value_range:\n",
        "        properties = base_properties.copy()\n",
        "        properties[var_to_plot] = val\n",
        "        features_to_classify.append(ee.Feature(None, properties))\n",
        "\n",
        "    fc_to_classify = ee.FeatureCollection(features_to_classify)\n",
        "\n",
        "    try:\n",
        "        classified_fc = fc_to_classify.classify(final_model, 'probability')\n",
        "        predictions = classified_fc.aggregate_array('probability').getInfo()\n",
        "\n",
        "        ax = axes[i]\n",
        "\n",
        "        if is_categorical:\n",
        "            bars = ax.bar(value_range, predictions, color='#2ca02c', alpha=0.8, width=0.6, edgecolor='black')\n",
        "            ax.set_xticks(value_range)\n",
        "\n",
        "        else:\n",
        "            ax.plot(value_range, predictions, lw=3, color='#2ca02c')\n",
        "            ax.fill_between(value_range, predictions, color='#2ca02c', alpha=0.1)\n",
        "\n",
        "        ax.set_xlabel(var_to_plot, fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel('Suitability (Probability)', fontsize=10)\n",
        "        ax.set_title(f'Response to {var_to_plot}', fontsize=14)\n",
        "        ax.grid(True, linestyle='--', alpha=0.5, axis='y')\n",
        "        ax.set_ylim(0, 1.05)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n{var_to_plot} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "for i in range(len(predictor_names), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "print(\"\\nëª¨ë“  ë°˜ì‘ ê³¡ì„  ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EY1wT9HcPX0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full Jackknife Test (ë³€ìˆ˜ ì¤‘ìš”ë„ ì •ë°€ ë¶„ì„)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- [Full Jackknife Test] ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„ ì‹œì‘ ---\")\n",
        "print(\" (1) ë‹¨ë… ëª¨ë¸(Solo), (2) ì œê±° ëª¨ë¸(Without), (3) ì „ì²´ ëª¨ë¸(Total) ë¹„êµ\")\n",
        "\n",
        "jackknife_results = []\n",
        "\n",
        "# ê¸°ì¡´ ì„¹ì…˜ 7ì—ì„œ ê³„ì‚°ëœ ì „ì²´ ëª¨ë¸ AUC í™œìš© (ì—†ì„ ê²½ìš° 0 ì²˜ë¦¬)\n",
        "total_auc_val = auc_score if 'auc_score' in locals() else 0\n",
        "print(f\" - ê¸°ì¤€ ëª¨ë¸(Total) AUC: {total_auc_val:.4f}\")\n",
        "\n",
        "# ë³€ìˆ˜ ë£¨í”„ ì‹œì‘\n",
        "for var in feature_bands:\n",
        "    # -------------------------------------------------------\n",
        "    # Solo Model (With Only): ì´ ë³€ìˆ˜ í•˜ë‚˜ë§Œ ì‚¬ìš©\n",
        "    # -------------------------------------------------------\n",
        "    try:\n",
        "        solo_model = ee.Classifier.amnhMaxent(\n",
        "            betaMultiplier=best_params.get('betaMultiplier', 1.0),\n",
        "            autoFeature=best_params.get('autoFeature', True),\n",
        "            addSamplesToBackground=True\n",
        "        ).train(\n",
        "            features=training_fc,\n",
        "            classProperty='pa',\n",
        "            inputProperties=[var]\n",
        "        )\n",
        "\n",
        "        # ì˜ˆì¸¡ ë° í‰ê°€\n",
        "        c_solo = testing_fc.classify(solo_model, 'probability')\n",
        "        d_solo = geemap.ee_to_df(c_solo.select(['pa', 'probability']))\n",
        "\n",
        "        # ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ íƒ€ì… ê°•ì œ ë³€í™˜\n",
        "        if not d_solo.empty:\n",
        "             d_solo['pa'] = d_solo['pa'].astype(int)\n",
        "             d_solo['probability'] = d_solo['probability'].astype(float)\n",
        "\n",
        "        if not d_solo.empty and len(d_solo['pa'].unique()) > 1:\n",
        "            solo_auc = roc_auc_score(d_solo['pa'], d_solo['probability'])\n",
        "        else:\n",
        "            solo_auc = 0.5 # ë°ì´í„° ë¶€ì¡± ì‹œ ëœë¤ ê°’ ì²˜ë¦¬\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   [Solo Error] {var}: {e}\")\n",
        "        solo_auc = 0.0\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # Without Model (Drop): ì´ ë³€ìˆ˜ë§Œ ë¹¼ê³  ë‚˜ë¨¸ì§€ ì‚¬ìš©\n",
        "    # -------------------------------------------------------\n",
        "    try:\n",
        "        # í˜„ì¬ ë³€ìˆ˜(var)ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
        "        drop_features = [b for b in feature_bands if b != var]\n",
        "\n",
        "        drop_model = ee.Classifier.amnhMaxent(\n",
        "            betaMultiplier=best_params.get('betaMultiplier', 1.0),\n",
        "            autoFeature=best_params.get('autoFeature', True),\n",
        "            addSamplesToBackground=True\n",
        "        ).train(\n",
        "            features=training_fc,\n",
        "            classProperty='pa',\n",
        "            inputProperties=drop_features\n",
        "        )\n",
        "\n",
        "        # ì˜ˆì¸¡ ë° í‰ê°€\n",
        "        c_drop = testing_fc.classify(drop_model, 'probability')\n",
        "        d_drop = geemap.ee_to_df(c_drop.select(['pa', 'probability']))\n",
        "\n",
        "        # ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ íƒ€ì… ê°•ì œ ë³€í™˜\n",
        "        if not d_drop.empty:\n",
        "             d_drop['pa'] = d_drop['pa'].astype(int)\n",
        "             d_drop['probability'] = d_drop['probability'].astype(float)\n",
        "\n",
        "        if not d_drop.empty and len(d_drop['pa'].unique()) > 1:\n",
        "            drop_auc = roc_auc_score(d_drop['pa'], d_drop['probability'])\n",
        "        else:\n",
        "            drop_auc = 0.5\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   [Without Error] {var}: {e}\")\n",
        "        drop_auc = 0.0\n",
        "\n",
        "    # ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥\n",
        "    print(f\"   > {var} : Solo={solo_auc:.4f} | Without={drop_auc:.4f}\")\n",
        "\n",
        "    jackknife_results.append({\n",
        "        'Variable': var,\n",
        "        'Solo AUC (Blue)': solo_auc,\n",
        "        'Without AUC (Green)': drop_auc,\n",
        "        'Total AUC (Red)': total_auc_val\n",
        "    })\n",
        "\n",
        "# ì‹œê°í™” (3ìƒ‰ ë§‰ëŒ€ ê·¸ë˜í”„)\n",
        "if jackknife_results:\n",
        "    df_res = pd.DataFrame(jackknife_results)\n",
        "    # Solo AUC(íŒŒë€ìƒ‰) ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
        "    df_res = df_res.sort_values(by='Solo AUC (Blue)', ascending=True)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, max(6, len(feature_bands) * 0.5))) # ë³€ìˆ˜ ê°œìˆ˜ì— ë”°ë¼ ë†’ì´ ì¡°ì ˆ\n",
        "\n",
        "    y_pos = range(len(df_res))\n",
        "    height = 0.25\n",
        "\n",
        "    # ë§‰ëŒ€ ê·¸ë¦¬ê¸°\n",
        "    # ğŸ”´ Total (ë°°ê²½ ê¸°ì¤€ì„  ì—­í• )\n",
        "    ax.barh([y + height for y in y_pos], df_res['Total AUC (Red)'], height,\n",
        "            label='With All Variables (Red)', color='#ff6666', alpha=0.6, edgecolor='white')\n",
        "\n",
        "    # ğŸŸ¢ Without (Drop)\n",
        "    ax.barh([y for y in y_pos], df_res['Without AUC (Green)'], height,\n",
        "            label='Without Variable (Green)', color='#66cc66', alpha=0.8, edgecolor='white')\n",
        "\n",
        "    # ğŸ”µ Solo (Only)\n",
        "    ax.barh([y - height for y in y_pos], df_res['Solo AUC (Blue)'], height,\n",
        "            label='With Only Variable (Blue)', color='#6666ff', alpha=0.8, edgecolor='white')\n",
        "\n",
        "    # ì¶• ë° ë ˆì´ë¸” ê¾¸ë¯¸ê¸°\n",
        "    ax.set_yticks(y_pos)\n",
        "    ax.set_yticklabels(df_res['Variable'], fontsize=11, fontweight='bold')\n",
        "    ax.set_xlabel('AUC Score', fontsize=12)\n",
        "    ax.set_title('Jackknife Test of Variable Importance', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # Xì¶• ë²”ìœ„ ì„¤ì •\n",
        "    try:\n",
        "        min_auc = min(df_res['Without AUC (Green)'].min(), df_res['Solo AUC (Blue)'].min())\n",
        "        ax.set_xlim(max(0.4, min_auc - 0.05), 1.02)\n",
        "    except:\n",
        "        ax.set_xlim(0.4, 1.0)\n",
        "\n",
        "    ax.legend(loc='lower right', frameon=True, shadow=True)\n",
        "    ax.grid(True, axis='x', linestyle='--', alpha=0.5)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"í•´ì„ íŒ:\")\n",
        "    print(\" 1. íŒŒë€ ë§‰ëŒ€ê°€ ê¸¸ìˆ˜ë¡: í•´ë‹¹ ë³€ìˆ˜ ìì²´ì˜ ì •ë³´ëŸ‰ì´ ë§ìŒ (ì¤‘ìš” ë³€ìˆ˜)\")\n",
        "    print(\" 2. ì´ˆë¡ ë§‰ëŒ€ê°€ ë¹¨ê°„ ë§‰ëŒ€ë³´ë‹¤ í˜„ì €íˆ ì§§ì„ìˆ˜ë¡: í•´ë‹¹ ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ ëª¨ë¸ ì„±ëŠ¥ì´ í•˜ë½í•¨ (ëŒ€ì²´ ë¶ˆê°€ ë³€ìˆ˜)\")\n",
        "else:\n",
        "    print(\"Jackknife ê²°ê³¼ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "dDkBY7ZWj4K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. ì˜ˆì¸¡ ì§€ë„ ìƒì„±"
      ],
      "metadata": {
        "id": "5NuXfK_ltuf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GEE Asset ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "user_asset_path = \"projects/ee-jjangmo91/assets\"\n",
        "\n",
        "asset_files = {\n",
        "    'elevation': 'elevation',\n",
        "    'slope': 'slope',\n",
        "    'northness': 'northness',\n",
        "    'tpi': 'tpi',\n",
        "    'twi': 'twi',\n",
        "    'tree_cover': 'tree_cover',\n",
        "    'forest_age': 'forest_age',\n",
        "    'forest_dmcls': 'forest_dmcls',\n",
        "    'forest_type': 'forest_type'\n",
        "}\n",
        "\n",
        "print(\"GEE Assetì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì™€ ë³‘í•©í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "img_list = []\n",
        "valid_bands = []\n",
        "\n",
        "for var_name, file_name in asset_files.items():\n",
        "    full_path = f\"{user_asset_path}/{file_name}\"\n",
        "    try:\n",
        "        img = ee.Image(full_path).rename(var_name).toFloat()\n",
        "        img_list.append(img)\n",
        "        valid_bands.append(var_name)\n",
        "    except Exception as e:\n",
        "        print(f\" [ë¡œë“œ ì‹¤íŒ¨] {var_name}: {e}\")\n",
        "\n",
        "if not img_list:\n",
        "    print(\" ë¶ˆëŸ¬ì˜¨ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "else:\n",
        "    predictors_final = ee.Image.cat(img_list)\n",
        "    print(f\" ì´ë¯¸ì§€ ë³‘í•© ì™„ë£Œ! (ë°´ë“œ ìˆ˜: {len(img_list)}ê°œ)\")\n",
        "\n",
        "    # ì„œì‹ì§€ ì í•©ì„± ì§€ë„ ìƒì„±\n",
        "    print(\"\\nMaxEnt ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì„œì‹ì§€ ì í•©ì„± ì§€ë„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.\")\n",
        "\n",
        "    # ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "    raw_output = predictors_final.select(valid_bands).classify(final_model)\n",
        "\n",
        "    # ë°´ë“œ í™•ì¸(ë””ë²„ê¹…)\n",
        "    output_bands = raw_output.bandNames().getInfo()\n",
        "    print(f\"ëª¨ë¸ ì¶œë ¥ ë°´ë“œ ëª©ë¡: {output_bands}\")\n",
        "    suitability_map = raw_output.select(0).rename('probability') \\\n",
        "                                .reproject(crs='EPSG:3857', scale=30)\n",
        "    vis_params = {\n",
        "        'min': 0, 'max': 1,\n",
        "        'palette': ['#440154', '#482677', '#404788', '#33638D', '#287D8E',\n",
        "                    '#1F968B', '#29AF7F', '#55C667', '#95D840', '#DCE319']\n",
        "    }\n",
        "\n",
        "    m = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "    m.add_basemap('HYBRID')\n",
        "    m.addLayer(suitability_map, vis_params, 'Habitat Suitability (Prob)')\n",
        "\n",
        "    # ì´ë¯¸ì§€ ê²½ê³„ì„ \n",
        "    tif_boundary = ee.Image().byte().paint(predictors_final.geometry(), 0, 2)\n",
        "    m.addLayer(tif_boundary, {'palette': 'black'}, 'Study Area Boundary')\n",
        "\n",
        "    # ì¶œí˜„ ì§€ì \n",
        "    if 'presence_fc' in locals():\n",
        "        m.addLayer(presence_fc.style(**{'color': 'red', 'pointSize': 3}), {}, 'Presence Points')\n",
        "\n",
        "    m.add_colorbar(vis_params, label=\"Probability (0~1)\", orientation=\"vertical\", layer_name=\"Habitat Suitability (Prob)\")\n",
        "\n",
        "    print(\"ì§€ë„ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "    display(m)"
      ],
      "metadata": {
        "id": "v8EkL-Jbkqsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì´ì§„(Binary) ì§€ë„ ìƒì„±\n",
        "if 'optimal_threshold' not in locals():\n",
        "    optimal_threshold = 0.510\n",
        "\n",
        "print(f\" ê³„ì‚°ëœ ìµœì  ì„ê³„ê°’({optimal_threshold})ì„ ì ìš©í•˜ì—¬ ì„œì‹ì§€ë¥¼ êµ¬ë¶„í•©ë‹ˆë‹¤.\")\n",
        "print(f\" (í™•ë¥ ì´ {optimal_threshold * 100:.1f}% ì´ìƒì¸ ê³³ë§Œ 'ì„œì‹ì§€'ë¡œ íŒë‹¨)\")\n",
        "\n",
        "# í™•ë¥  >= ì„ê³„ê°’\n",
        "potential_distribution = suitability_map.gt(optimal_threshold)\n",
        "\n",
        "# ì‹œê°í™”\n",
        "binary_vis = {'min': 0, 'max': 1, 'palette': ['#D3D3D3', '#006400']}\n",
        "\n",
        "m2 = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "m2.add_basemap('HYBRID')\n",
        "\n",
        "m2.addLayer(potential_distribution, binary_vis, 'Potential Distribution (Binary)')\n",
        "m2.addLayer(ee.Image().byte().paint(predictors_final.geometry(), 0, 2), {'palette': 'black'}, 'Study Area Boundary')\n",
        "\n",
        "if 'presence_fc' in locals():\n",
        "    m2.addLayer(presence_fc.style(**{'color': 'red', 'pointSize': 3}), {}, 'Presence Points')\n",
        "\n",
        "# ë²”ë¡€\n",
        "legend_keys = ['Suitable Habitat', 'Unsuitable Habitat', 'Presence Points']\n",
        "legend_colors = ['#006400', '#D3D3D3', '#FF0000']\n",
        "m2.add_legend(title=\"Distribution Legend\", labels=legend_keys, colors=legend_colors)\n",
        "\n",
        "print(\"ì ì¬ ë¶„í¬ ì§€ë„ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "display(m2)"
      ],
      "metadata": {
        "id": "zQCu1reetrvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. ì„œì‹ì§€ ì í•©ì„± 5ë“±ê¸‰ ë¶„ë¥˜ ë° ë©´ì  ì‚°ì¶œ\n"
      ],
      "metadata": {
        "id": "EI3lO209iLM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¶„ì„ ë²”ìœ„ ì„¤ì •\n",
        "if 'predictors_final' in locals():\n",
        "    study_geometry = predictors_final.geometry()\n",
        "else:\n",
        "    print(\"ì£¼ì˜: ì´ë¯¸ì§€ ë²”ìœ„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "# ë“±ê¸‰ ë¶„ë¥˜ (Reclassification)\n",
        "classified_map = suitability_map.expression(\n",
        "    \"(b('probability') > 0.8) ? 1 :\" +\n",
        "    \"(b('probability') > 0.6) ? 2 :\" +\n",
        "    \"(b('probability') > 0.4) ? 3 :\" +\n",
        "    \"(b('probability') > 0.2) ? 4 : 5\"\n",
        ").rename('grade').toInt()\n",
        "\n",
        "# ë©´ì  ì‚°ì¶œ (Area Calculation)\n",
        "print(\"ë“±ê¸‰ë³„ ë©´ì ì„ ê³„ì‚° ì¤‘ì…ë‹ˆë‹¤... (ì•½ê°„ì˜ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤)\")\n",
        "\n",
        "# í”½ì…€ ë©´ì  ì´ë¯¸ì§€ ìƒì„± ë° ê²°í•©\n",
        "pixel_area = ee.Image.pixelArea()\n",
        "classification_with_area = pixel_area.addBands(classified_map)\n",
        "\n",
        "# reduceRegion ì‹¤í–‰\n",
        "area_stats = classification_with_area.reduceRegion(\n",
        "    reducer=ee.Reducer.sum().group(\n",
        "        groupField=1, groupName='grade'\n",
        "    ),\n",
        "    geometry=study_geometry,\n",
        "    scale=30,      # í•´ìƒë„ 30m\n",
        "    maxPixels=1e13\n",
        ")\n",
        "\n",
        "# ê²°ê³¼ ì •ë¦¬\n",
        "stats_list = area_stats.get('groups').getInfo()\n",
        "df_area = pd.DataFrame(stats_list)\n",
        "\n",
        "if not df_area.empty:\n",
        "    # ë‹¨ìœ„ ë³€í™˜ (m^2 -> km^2)\n",
        "    df_area['area_km2'] = df_area['sum'] / 1_000_000\n",
        "    df_area['grade'] = df_area['grade'].astype(int)\n",
        "\n",
        "    # ë¹„ìœ¨(%) ê³„ì‚°\n",
        "    total_area = df_area['area_km2'].sum()\n",
        "    df_area['ratio_percent'] = (df_area['area_km2'] / total_area) * 100\n",
        "\n",
        "    # ì •ë ¬ ë° ë¼ë²¨ë§\n",
        "    df_area = df_area.sort_values('grade')\n",
        "    grade_labels = {\n",
        "        1: 'Grade 1 (0.8~1.0)',\n",
        "        2: 'Grade 2 (0.6~0.8)',\n",
        "        3: 'Grade 3 (0.4~0.6)',\n",
        "        4: 'Grade 4 (0.2~0.4)',\n",
        "        5: 'Grade 5 (0.0~0.2)'\n",
        "    }\n",
        "    df_area['label'] = df_area['grade'].map(grade_labels)\n",
        "\n",
        "    print(\"\\n[ë“±ê¸‰ë³„ ë©´ì  ì‚°ì¶œ ê²°ê³¼]\")\n",
        "    print(df_area[['label', 'area_km2', 'ratio_percent']].to_string(index=False, float_format=\"%.2f\"))\n",
        "    print(f\"\\n - ë¶„ì„ëœ ì´ ë©´ì : {total_area:.2f} kmÂ²\")\n",
        "else:\n",
        "    print(\"ë©´ì  ê³„ì‚° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "id": "bny5KcrHiGzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. ê²°ê³¼ ì‹œê°í™” (ë©´ì  ê·¸ë˜í”„ & ë“±ê¸‰ ì§€ë„)"
      ],
      "metadata": {
        "id": "duyH-pvsir5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê·¸ë˜í”„ ì„¤ì •\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# ìƒ‰ìƒ ì§€ì • (1ë“±ê¸‰: ì§„ë…¹ìƒ‰ -> 5ë“±ê¸‰: íšŒìƒ‰)\n",
        "color_palette = ['#006400', '#74C476', '#FFFF00', '#FF7F00', '#A9A9A9']\n",
        "bars = plt.bar(df_area['label'], df_area['area_km2'],\n",
        "               color=color_palette, edgecolor='black', alpha=0.8)\n",
        "plt.title('Area by Habitat Suitability Grade', fontsize=15, fontweight='bold')\n",
        "plt.xlabel('Suitability Grade', fontsize=12)\n",
        "plt.ylabel('Area (kmÂ²)', fontsize=12)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "total_area = df_area['area_km2'].sum()\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    pct = (height / total_area) * 100\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, height,\n",
        "             f'{height:.1f} kmÂ²\\n({pct:.1f}%)',\n",
        "             ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eOVRewNFirWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = geemap.Map(center=[36.54, 127.83], zoom=11, height='600px', width='1000px')\n",
        "m.add_basemap('HYBRID')\n",
        "\n",
        "grade_vis_params = {\n",
        "    'min': 1,\n",
        "    'max': 5,\n",
        "    'palette': ['#006400', '#74C476', '#FFFF00', '#FF7F00', '#A9A9A9']\n",
        "}\n",
        "\n",
        "m.addLayer(classified_map, grade_vis_params, 'Suitability Grades (1-5)')\n",
        "\n",
        "if 'predictors_final' in locals():\n",
        "    boundary_img = ee.Image().byte().paint(predictors_final.geometry(), 0, 2)\n",
        "    m.addLayer(boundary_img, {'palette': 'black'}, 'Study Area Boundary')\n",
        "\n",
        "legend_dict = {\n",
        "    'Grade 1 (High Prob)': '#006400',\n",
        "    'Grade 2': '#74C476',\n",
        "    'Grade 3': '#FFFF00',\n",
        "    'Grade 4': '#FF7F00',\n",
        "    'Grade 5 (Low Prob)': '#A9A9A9'\n",
        "}\n",
        "m.add_legend(title=\"Habitat Grades\", legend_dict=legend_dict)\n",
        "m.add_layer_control()\n",
        "display(m)"
      ],
      "metadata": {
        "id": "tTlhSGWWr-wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"
      ],
      "metadata": {
        "id": "q2_IS7cjtWjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- ê²°ê³¼ ë‚´ë³´ë‚´ê¸° (GeoTIFF) ì‹œì‘ ---\")\n",
        "\n",
        "# ì €ì¥í•  ê²½ë¡œ ì„¤ì •\n",
        "output_folder = '/content/drive/MyDrive/KNPS/Siberian flying squirrel/data/'\n",
        "output_tif_path = os.path.join(output_folder, 'result_suitability_grade_v1.tif')\n",
        "\n",
        "# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "print(f\"íŒŒì¼ ì €ì¥ ê²½ë¡œ:\\n{output_tif_path}\")\n",
        "\n",
        "# ë‚´ë³´ë‚¼ ì˜ì—­ ì„¤ì • (ì´ë¯¸ì§€ ë²”ìœ„ ì‚¬ìš©)\n",
        "if 'predictors_final' in locals():\n",
        "    export_region = predictors_final.geometry()\n",
        "else:\n",
        "    print(\"predictors_final ë³€ìˆ˜ê°€ ì—†ì–´ region ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ë‚´ë³´ë‚´ê¸° ìˆ˜í–‰\n",
        "if export_region:\n",
        "    print(\"ì§€ë„ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... (ì§„í–‰ë¥ ì´ í‘œì‹œë©ë‹ˆë‹¤)\")\n",
        "\n",
        "    try:\n",
        "        geemap.ee_export_image(\n",
        "            classified_map,\n",
        "            filename=output_tif_path,\n",
        "            scale=30,\n",
        "            region=export_region,\n",
        "            crs='EPSG:5186',\n",
        "            file_per_band=False\n",
        "        )\n",
        "        print(\"\\n TIF ì €ì¥ ì™„ë£Œ! ë“œë¼ì´ë¸Œ í´ë”ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "else:\n",
        "    print(\" ë‚´ë³´ë‚¼ ì˜ì—­(region)ì´ ì •ì˜ë˜ì§€ ì•Šì•„ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "id": "QzKLrKb9tUFW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}